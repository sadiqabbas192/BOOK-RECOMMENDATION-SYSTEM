# -*- coding: utf-8 -*-
"""FLIPKART WEB SCRAPPING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SjSUWYI8VWDLfCXrEt5rT47qjVuMOHpK

#**WEB SCRAPING**

###**IMPORTS**
"""

!pip install beautifulsoup
!pip install selenium
!pip install requests

from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import requests

"""###**METHODS FOR CONVERSION**"""

#METHOD 1 - converting to string
def passInList(authors):
       return (', '.join(authors))

#METHOD 2 - removing space and adding to a new List
def Convert(string):
    li = list(string.split("   "))
    return li

"""###**METHOD FOR SCRAPPING**"""

def scrap_books_to_df(url, rows):
  title = []
  ratings = []
  common = []
  lang = []
  format = []
  authors = []
  tags = []
  
  #Electronics And Communications Engineering Books
  pages  = list(range(1,21))
  for page in pages:
    response = requests.get(url=url.format(page))
    htmlcontent = response.content
    soup = BeautifulSoup(htmlcontent, "html.parser")

    #extracting book title
    get_title = soup.find_all('a', class_ = 's1Q9rs')
    for i in range(len(get_title)):
      title.append(get_title[i].text)
    
    #extracting ratings
    get_ratings = soup.find_all('div', class_ = '_3LWZlK')
    for i in range(len(get_ratings)):
      ratings.append(get_ratings[i].text)

    #extracting tags 
    get_tags = soup.find_all('h1', class_ = '_10Ermr')
    for i in range(len(get_tags)):
      tags.append(get_tags[i].text)

    #extracting common class
    common = soup.find_all('div', class_ = '_3Djpdu')
    for i in range(0, len(common)):
      p = common[i].text
      
      if ("English" in p):
        lang.append("English")
      elif ("Hindi" in p):
        lang.append("Hindi")
      elif ("Marathi" in p):
        lang.append("Marathi")
      else:
        lang.append("")
      
      if ("Paperback" in p):
        format.append("Paperback")
      elif ("Hardcover" in p):
        format.append("Hardcover")
      else:
        format.append("Undefined")

      if ("English" in p and "Paperback" in p):
        p = p.replace("English", "")
        p = p.replace("Paperback", "")
        authors.append(p)
      elif ("English" in p and "Hardcover" in p):
        p = p.replace("English", "")
        p = p.replace("Hardcover", "")
        authors.append(p)
      elif ("English" in p and "Undefined" in p):
        p = p.replace("English", "")
        p = p.replace("Undefined", "")
        authors.append(p)

      elif ("Hindi" in p and "Paperback" in p):
        p = p.replace("Hindi", "")
        p = p.replace("Paperback", "")
        authors.append(p)
      elif ("Hindi" in p and "Hardcover" in p):
        p = p.replace("Hindi", "")
        p = p.replace("Hardcover", "")
        authors.append(p)
      elif ("Hindi" in p and "Undefined" in p):
        p = p.replace("Hindi", "")
        p = p.replace("Undefined", "")
        authors.append(p)

      elif ("Marathi" in p and "Paperback" in p):
        p = p.replace("Marathi", "")
        p = p.replace("Paperback", "")
        authors.append(p)
      elif ("Marathi" in p and "Hardcover" in p):
        p = p.replace("Hindi", "")
        p = p.replace("Hardcover", "")
        authors.append(p)
      elif ("Marathi" in p and "Undefined" in p):
        p = p.replace("Hindi", "")
        p = p.replace("Undefined", "")
        authors.append(p)

      else:
          authors.append(p)   
      

  string_authors = passInList(authors)
  string_authors = string_authors.replace(',',"")
  #print(string_authors)
  new_authors = Convert(string_authors)
  #print(new_authors)  

  i = 1
  value = tags[0]
  while(i<=rows):
    tags.append(value)
    i=i+1


  print("-----------------")
  print("title")
  print(title)
  print(len(title))
  print("-----------------")

  print("ratings")
  print(ratings)
  print(len(ratings))
  print("-----------------")

  print("lang")
  print(lang)
  print(len(lang))
  print("-----------------")

  print("format")
  print(format)
  print(len(format))
  print("-----------------")

  print("new_authors")
  print(new_authors)
  print(len(new_authors))
  print("-----------------")

  print("tags")
  print(tags)
  print(len(tags))
  print("-----------------")

  df = pd.DataFrame({"title":title[slice(rows)],
                    "authors":new_authors[slice(rows)],
                    "ratings":ratings[slice(rows)],
                    "lang":lang[slice(rows)],
                    "format":format[slice(rows)],
                    "tags":tags[slice(rows)]})
  return df



"""###**CALLING THE METHOD**"""

#Electronic Engg
url = "https://www.flipkart.com/books/higher-education-and-professional-books/electronics-and-communications-engineering-books/pr?sid=bks%2Cf50%2Cpw8&otracker=categorytree&"
df1 = scrap_books_to_df(url, 600)
df1

#Mechanical Engg
url = "https://www.flipkart.com/books/higher-education-and-professional-books/mechanical-engineering-and-material-books/pr?sid=bks,f50,kf5&otracker=categorytree&"
df2 = scrap_books_to_df(url, 500)
df2

#Law Books
url ="https://www.flipkart.com/books/higher-education-and-professional-books/law-books/pr?sid=bks,f50,9pq&otracker=categorytree&"
df4 = scrap_books_to_df(url, 500)
df4

#Economics
url = "https://www.flipkart.com/books/economics-business-and-management-books/economics-books/pr?sid=bks,xjk,u8r&otracker=categorytree&"
df5 = scrap_books_to_df(url, 600)
df5

#Science Finction
url = "https://www.flipkart.com/books/fiction-books/science-fiction-books/pr?sid=bks,wbi,hax&otracker=categorytree&"
df6 = scrap_books_to_df(url, 600)
df6

#Crime Mystry
url = "https://www.flipkart.com/books/fiction-books/crime-mystery-and-thriller-books/pr?sid=bks,wbi,mbl&otracker=categorytree&"
df7 = scrap_books_to_df(url, 700)
df7

#General Fiction
url = "https://www.flipkart.com/books/fiction-books/general-fiction-books/pr?sid=bks,wbi,noa&otracker=categorytree&"
df8 = scrap_books_to_df(url, 700)

#Polotical Science
url = "https://www.flipkart.com/books/social-science-books/politics-books/pr?sid=bks,rbc,afq&otracker=categorytree&"
df9 = scrap_books_to_df(url, 700)

#Psychology
url = "https://www.flipkart.com/books/social-science-books/psychology-books/pr?sid=bks,rbc,th4&otracker=categorytree"
df10 = scrap_books_to_df(url, 700)

#Litrature
url = "https://www.flipkart.com/books/literature-books/pr?sid=bks,w4n&otracker=categorytree&"
df11 = scrap_books_to_df(url, 700)
df11

#Humor
url = "https://www.flipkart.com/books/lifestyle-hobby-and-sport-books/humour-books/pr?sid=bks,wcr,8nw&otracker=categorytree&"
df12 = scrap_books_to_df(url, 700)
df12

"""###**MERGING DATAFRAMES AND CREATING CSV**"""

frames = [df1, df2, df4, df5, df6, df7, df8, df9, df10, df11, df12]
result = pd.concat(frames)
result

result.to_csv('Flipkart.csv')